{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28351,
     "status": "ok",
     "timestamp": 1744709215260,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "NDDPqEOuEFFj",
    "outputId": "8ca33089-d537-4170-9afc-eea49011f524"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B1Z8zU8ZQlY"
   },
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6133,
     "status": "ok",
     "timestamp": 1744709224501,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "Pv20JUPs5AaM",
    "outputId": "7f0a237f-11db-404a-9cb2-46175d6db884"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4856,
     "status": "ok",
     "timestamp": 1744709229358,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "jtpL-XF95VeW",
    "outputId": "d4938ecb-7cbf-404b-9c66-5cf3f9117c33"
   },
   "outputs": [],
   "source": [
    "!pip install finrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115796,
     "status": "ok",
     "timestamp": 1744709346850,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "vKrYcSy25YNu",
    "outputId": "b2a5900f-6b1b-4d10-b7d7-e9266fd0168b"
   },
   "outputs": [],
   "source": [
    "!pip install stable_baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108632,
     "status": "ok",
     "timestamp": 1744709488810,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "jFMgxdxQ5dD4",
    "outputId": "469d70ec-8b41-4a87-805c-7481d5db7598"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7773,
     "status": "ok",
     "timestamp": 1744709498730,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "11Hoa_0F5iO0",
    "outputId": "ba9fc13c-9d49-4798-9703-84ef263b8c24"
   },
   "outputs": [],
   "source": [
    "!pip install pandas_market_calendars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1020,
     "status": "ok",
     "timestamp": 1744709501208,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "sEQeZUyv5pwr",
    "outputId": "ac9ed2db-ca07-44a1-9341-ace3faa35d67"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/benstaf/FinRL_DeepSeek.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2396,
     "status": "ok",
     "timestamp": 1744709505585,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "2BISBoRj50vu",
    "outputId": "ad65c0a1-7c05-4936-ea9a-ae0d82565536"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/benstaf/spinningup_pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 264225,
     "status": "ok",
     "timestamp": 1744709773295,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "lrb6cHZg6Nfm",
    "outputId": "7edaef8b-3787-4b46-b15f-63b86a1536ed"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install numpy scipy gymnasium pandas matplotlib seaborn\n",
    "!pip install mpi4py tqdm cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22304,
     "status": "ok",
     "timestamp": 1744709820265,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "N3S4sdCD6Nib",
    "outputId": "b01750dd-a65b-4940-9e4b-8bdc79e8ff44"
   },
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y swig cmake build-essential\n",
    "!pip install --upgrade pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78611,
     "status": "ok",
     "timestamp": 1744709911441,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "R7T8EHGE6NlN",
    "outputId": "944ccc42-9f1e-485e-a8d9-5b7609436109"
   },
   "outputs": [],
   "source": [
    "!pip install box2d box2d-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11634,
     "status": "ok",
     "timestamp": 1744709923077,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "o0FzY9iC6Non",
    "outputId": "fb030d2a-ab36-4157-8e26-0e478fa6de51"
   },
   "outputs": [],
   "source": [
    "!pip install \"gym==0.15.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2022,
     "status": "ok",
     "timestamp": 1744709957215,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "c74uPIuU0Egx",
    "outputId": "0fe9e90a-6d6b-4a5f-b9d5-70870d255103"
   },
   "outputs": [],
   "source": [
    "!pip install mpi4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1744709961241,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "4wbg2iWSZAcj",
    "outputId": "6f5b560a-8700-4b2c-fd45-fde4bf40c1d3"
   },
   "outputs": [],
   "source": [
    "%cd /content/spinningup_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4216,
     "status": "ok",
     "timestamp": 1744710002551,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "KnZIFI1G7STk",
    "outputId": "6bdb4aeb-d155-4996-e812-9440d88e0b0e"
   },
   "outputs": [],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AWIRTyxZMBP"
   },
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QL8ENCUO7SfU"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/FinRL_DeepSeek/\")  # Adjust path to root folder\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "#from finrl.main import check_and_make_directories\n",
    "#from env_stocktrading import StockTradingEnv\n",
    "import os\n",
    "\n",
    "def check_and_make_directories(directories):\n",
    "    for directory in directories:\n",
    "        os.makedirs(\"./\" + directory, exist_ok=True)  # This prevents FileEx>\n",
    "\n",
    "\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])\n",
    "sys.path.append(\"/content/spinningup_pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95loKIqs7SiL"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "#from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "from finrl.main import check_and_make_directories\n",
    "from env_stocktrading_llm_01 import StockTradingEnv\n",
    "\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpH8yn6DZHG-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import spinup.algos.pytorch.ppo.core as core\n",
    "from spinup.utils.logx import EpochLogger\n",
    "from spinup.utils.mpi_pytorch import setup_pytorch_for_mpi, sync_params, mpi_avg_grads\n",
    "from spinup.utils.mpi_tools import mpi_fork, mpi_avg, proc_id, mpi_statistics_scalar, num_procs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ik4PAxARZJ3a"
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJO7Cu-7GFU7"
   },
   "source": [
    "## Train data - benstaf train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297,
     "referenced_widgets": [
      "b361154eef7f4fe4bd9a86507177b893",
      "e9194524c5d843588c7b3f703099ff58",
      "f9f6aebf33754f37b9bc6e4cc4d287ac",
      "f9860896c6874eb2b785f34b23788fa9",
      "64d74c163c354a1985380bcbe5d136b7",
      "8a7d1091fb86416bb54cf63894573ae3",
      "4a328d17ae2047c7ad889887133c18b2",
      "363b92ecc9cd42599bfe920cdedf1ac6",
      "b9d1c20db240488b85df7ff38b65e12b",
      "d17f19d0f4b14bef976c7c3730006ecb",
      "83ecc68c4f784cfdadf780909499bb87",
      "e358908327254e5db48fc8d44efafa08",
      "1d548c00cb4f4b14969551da1a7e4bb0",
      "f9f3aea138f446bc8b75d5970c909025",
      "f18f69110e514bcc90dc3ce769430811",
      "66dee62bb472498f84705eb5018342f0",
      "ecce6be7b44b4e81abf77b1742accc85",
      "773765f711ac4c1588004d2e83e42de7",
      "6dee4e080884465886bebc88242936a7",
      "40f9327cce5c4a84996a31782e6ce756",
      "5f92eec74cb24a98b443c8443091444f",
      "250ae613e0534db58a975b567e6ceae0",
      "3d38c189cb8b494abf4a7e296c648143",
      "27c3867f583d41998f32c8ec66c7c941",
      "078504f804d04f01906a24e09a9c971b",
      "91c6b7ebbb0f4abc94e7e3940dd94f0d",
      "e4ef9282c35e46e882d94158a7edcc84",
      "fe09d0b264184aa8a34c45075950829e",
      "16b7182d88c944788bb022c3c7bef310",
      "85c712ddfd68480f8e3790654f6aa6a2",
      "54f4d72c1e03437496e5abcd64566a1d",
      "604c35e508e7481a9b4a664e14c947c5",
      "9a7c4d41491b4a4483d7b5590e4f94e8"
     ]
    },
    "executionInfo": {
     "elapsed": 33866,
     "status": "ok",
     "timestamp": 1744710535663,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "_JlTr7sy7SlX",
    "outputId": "50aa05fd-1f72-41ed-d7a1-da464a2da4c3"
   },
   "outputs": [],
   "source": [
    "#train = pd.read_csv('train_data2.csv')\n",
    "#dataset = load_dataset(\"benstaf/train_data_qwen_sentiment\", data_files=\"train_data_qwen_sentiment.csv\")\n",
    "dataset = load_dataset(\"benstaf/nasdaq_2013_2023\", data_files=\"train_data_deepseek_sentiment_2013_2018.csv\")\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "train = pd.DataFrame(dataset['train'])\n",
    "\n",
    "#train = pd.read_csv('train_data_qwen_sentiment.csv')\n",
    "\n",
    "train = train.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "# Create a new index based on unique dates\n",
    "unique_dates = train['date'].unique()\n",
    "date_to_idx = {date: idx for idx, date in enumerate(unique_dates)}\n",
    "\n",
    "# Create new index based on the date mapping\n",
    "train['new_idx'] = train['date'].map(date_to_idx)\n",
    "\n",
    "# Set this as the index\n",
    "train = train.set_index('new_idx')\n",
    "\n",
    "\n",
    "#missing values with 0\n",
    "train['llm_sentiment'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# If you are not using the data generated from part 1 of this tutorial, make sure\n",
    "# it has the columns and index in the form that could be make into the environment.\n",
    "# Then you can comment and skip the following two lines.\n",
    "#train = train.set_index(train.columns[0])\n",
    "#train.index.names = ['']\n",
    "\n",
    "\n",
    "# ## Construct the environment\n",
    "\n",
    "# Calculate and specify the parameters we need for constructing the environment.\n",
    "\n",
    "# In[16]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1744710566660,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "Cj7Wgim47Sot",
    "outputId": "78a3377c-8e9f-4e04-ba1f-70b28cb56062"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOKSAkGCLDiR"
   },
   "outputs": [],
   "source": [
    "train.to_csv('/content/drive/MyDrive/FinRL/Data/Input/train_data_deepseek_sentiment_2013_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1744710659215,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "rhqAe4zjfn7T",
    "outputId": "a401c1ea-435b-44fa-9d0a-9772b598145f"
   },
   "outputs": [],
   "source": [
    "train.dtypes.reset_index().rename(columns={\"index\": \"Column\", 0: \"Data Type\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9Hv1gZRRBmM"
   },
   "source": [
    "## Reduce to selected 9 Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCalfQ6xkKxT"
   },
   "outputs": [],
   "source": [
    "# Step 2: Filter by tickers and date range\n",
    "tickers = ['AMD', 'ADBE', 'PYPL', 'CSCO', 'NFLX', 'NVDA', 'EBAY', 'MNST', 'GOOGL']\n",
    "train = train[\n",
    "    (train['tic'].isin(tickers)) &\n",
    "    (train['date'] >= '2018-06-14') &\n",
    "    (train['date'] <= '2018-12-28')\n",
    "].sort_values(by='date')\n",
    "\n",
    "# Step 3: Create a mapping from unique dates to a new index\n",
    "date_to_idx = {date: idx for idx, date in enumerate(sorted(train['date'].unique()))}\n",
    "\n",
    "# Step 4: Map that to a new column\n",
    "train['new_idx'] = train['date'].map(date_to_idx)\n",
    "\n",
    "# Step 5: Set new_idx as the actual DataFrame index\n",
    "train.set_index('new_idx', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7zood03xZkS"
   },
   "outputs": [],
   "source": [
    "# Drop the 'new_idx' column (not the index!)\n",
    "if 'new_idx' in train.columns:\n",
    "    train.drop(columns='new_idx', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1744710867305,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "lpHX3xv3DRQG",
    "outputId": "5c584f11-b8ca-47c6-fff3-21e280dbb4d1"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1744710869778,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "vsR7fULAPwp_",
    "outputId": "b9191a10-79a7-41ea-dba1-f7b2276a3e77"
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1744710870569,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "rtsnkCElPoGw",
    "outputId": "9d172195-b6b3-470a-d719-153bb5302218"
   },
   "outputs": [],
   "source": [
    "train['tic'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZC5YSHAZRLR6"
   },
   "source": [
    "## Get Deepseek Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1744710887585,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "w30XgJh6RSsJ",
    "outputId": "047cdcfa-7a27-460d-d98a-b85073faa411"
   },
   "outputs": [],
   "source": [
    "deepseek_sentiments = pd.read_csv(\"/content/drive/MyDrive/FinRL/Data/Input/Test_One/_dataset_scored_combined.csv\")\n",
    "deepseek_sentiments.shape, deepseek_sentiments.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEGoSFeQ-7rB"
   },
   "source": [
    "### Remove rows where 'price' column has NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5Hqymb7Z_tZ"
   },
   "outputs": [],
   "source": [
    "# Remove rows where 'price' column has NaN values\n",
    "deepseek_sentiments = deepseek_sentiments.dropna(subset=['Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwdzzGOt_Beo"
   },
   "source": [
    "### Confirm Train Data and Deepseek Data have the same dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1744710890828,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "43bqOLMiZlXf",
    "outputId": "1da22211-340b-48d1-bd85-e8cd02da7ff5"
   },
   "outputs": [],
   "source": [
    "deepseek_sentiments['Date'].nunique(), train['date'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1744710892383,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "Dhr-SmSXZTLE",
    "outputId": "9d6809bf-dc8e-4b50-d56e-855420da968d"
   },
   "outputs": [],
   "source": [
    "hm_dates = list(deepseek_sentiments['Date'].unique())\n",
    "t_dates = list(train['date'].unique())\n",
    "\n",
    "if hm_dates==t_dates:\n",
    "  print(\"Dates are the same\")\n",
    "else:\n",
    "  print(\"Dates are not the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcT6C7q8RfLB"
   },
   "source": [
    "## Replace LLM Sentiments in Train with Weighted Averages of Deepseek Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1744710893301,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "UANbaUr32rWE",
    "outputId": "026b1031-8c25-4292-8669-106620dfa99d"
   },
   "outputs": [],
   "source": [
    "df = deepseek_sentiments.copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDis0MODRezc"
   },
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "  date = row['date']\n",
    "  tic = row['tic']\n",
    "  sentiment_before = row['llm_sentiment']\n",
    "  sub = df[(df['Date'] == date) & (df['Stock_symbol'] == tic)]\n",
    "\n",
    "  if not sub.empty:\n",
    "    sentiments = list(sub['deepseek_sentiment'])\n",
    "    total_news = len(sentiments)\n",
    "    counts = {i: sentiments.count(i) for i in range(1, 6)}\n",
    "\n",
    "    # Calculate weighted average\n",
    "    weighted_sum = sum(value * count for value, count in counts.items())\n",
    "    weighted_avg = weighted_sum / total_news\n",
    "    train.at[index, 'llm_sentiment'] = round(weighted_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1744710915741,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "mmPv33pueJ4z",
    "outputId": "68888d7b-8f76-4605-e503-e4521e04c343"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8dxC0xDedip"
   },
   "outputs": [],
   "source": [
    "# Replace NaN values in column 'A' with 0\n",
    "train['llm_sentiment'] = train['llm_sentiment'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tG3jgdaNksR"
   },
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1744710924908,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "1BZBnsV3gKUF",
    "outputId": "bedcbe64-01bc-40ce-fd7a-3f479278f792"
   },
   "outputs": [],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + (1+ len(INDICATORS))*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1744710927104,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "b7gj817xx8Je",
    "outputId": "6c35f7af-0727-4147-e1ef-043f7693df4a"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1744710928189,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "8fRMUSBB9paq",
    "outputId": "e49598d5-fcec-415f-d2aa-766e6f027be5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "\n",
    "# ## Environment for training\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "#print(type(env_train))\n",
    "\n",
    "\n",
    "# Initialize the environment\n",
    "#env_train, _ = e_train_gym.get_sb_env()\n",
    "\n",
    "# Check the observation space\n",
    "print(\"Observation space:\", env_train.observation_space)\n",
    "print(\"Observation space shape:\", env_train.observation_space.shape)\n",
    "\n",
    "# Reset the environment and check the observation returned\n",
    "obs = env_train.reset()\n",
    "print(\"Observation returned from reset:\", obs.shape)\n",
    "\n",
    "\n",
    "\n",
    "# # Part 3: Train DRL Agents\n",
    "# * Here, the DRL algorithms are from **[Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/)**. It's a library that implemented popular DRL algorithms using pytorch, succeeding to its old version: Stable Baselines.\n",
    "# * Users are also encouraged to try **[ElegantRL](https://github.com/AI4Finance-Foundation/ElegantRL)** and **[Ray RLlib](https://github.com/ray-project/ray)**.\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "#Custom PPO agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3C3UmaLgZni"
   },
   "outputs": [],
   "source": [
    "def combined_shape(length, shape=None):\n",
    "    if shape is None:\n",
    "        return (length,)\n",
    "    return (length, shape) if np.isscalar(shape) else (length, *shape)\n",
    "\n",
    "\n",
    "def mlp(sizes, activation, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        act = activation if j < len(sizes)-2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def count_vars(module):\n",
    "    return sum([np.prod(p.shape) for p in module.parameters()])\n",
    "\n",
    "\n",
    "def discount_cumsum(x, discount):\n",
    "    \"\"\"\n",
    "    magic from rllab for computing discounted cumulative sums of vectors.\n",
    "\n",
    "    input:\n",
    "        vector x,\n",
    "        [x0,\n",
    "         x1,\n",
    "         x2]\n",
    "\n",
    "    output:\n",
    "        [x0 + discount * x1 + discount^2 * x2,\n",
    "         x1 + discount * x2,\n",
    "         x2]\n",
    "    \"\"\"\n",
    "    return scipy.signal.lfilter([1], [1, float(-discount)], x[::-1], axis=0)[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Shxdp2dYgeJM"
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "\n",
    "    def _distribution(self, obs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _log_prob_from_distribution(self, pi, act):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, obs, act=None):\n",
    "        # Produce action distributions for given observations, and\n",
    "        # optionally compute the log likelihood of given actions under\n",
    "        # those distributions.\n",
    "        pi = self._distribution(obs)\n",
    "        logp_a = None\n",
    "        if act is not None:\n",
    "            logp_a = self._log_prob_from_distribution(pi, act)\n",
    "        return pi, logp_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhEXO6_VggXZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLPCategoricalActor(Actor):\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation):\n",
    "        super().__init__()\n",
    "        self.logits_net = mlp([obs_dim] + list(hidden_sizes) + [act_dim], activation)\n",
    "\n",
    "    def _distribution(self, obs):\n",
    "        logits = self.logits_net(obs)\n",
    "        return Categorical(logits=logits)\n",
    "\n",
    "    def _log_prob_from_distribution(self, pi, act):\n",
    "        return pi.log_prob(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikPy3cOigihA"
   },
   "outputs": [],
   "source": [
    "class MLPGaussianActor(Actor):\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation):\n",
    "        super().__init__()\n",
    "        log_std = -0.5 * np.ones(act_dim, dtype=np.float32)\n",
    "        self.log_std = torch.nn.Parameter(torch.as_tensor(log_std))\n",
    "        self.mu_net = mlp([obs_dim] + list(hidden_sizes) + [act_dim], activation)\n",
    "\n",
    "    def _distribution(self, obs):\n",
    "        mu = self.mu_net(obs)\n",
    "        std = torch.exp(self.log_std)\n",
    "        return Normal(mu, std)\n",
    "\n",
    "    def _log_prob_from_distribution(self, pi, act):\n",
    "        return pi.log_prob(act).sum(axis=-1)    # Last axis sum needed for Torch Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2scY_YgHglAa"
   },
   "outputs": [],
   "source": [
    "class MLPCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_dim, hidden_sizes, activation):\n",
    "        super().__init__()\n",
    "        self.v_net = mlp([obs_dim] + list(hidden_sizes) + [1], activation)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        return torch.squeeze(self.v_net(obs), -1) # Critical to ensure v has right shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhlVsowy9pl2"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLPActorCritic(nn.Module):\n",
    "    def __init__(self, observation_space, action_space,\n",
    "                 hidden_sizes=(64, 64), activation=nn.Tanh):\n",
    "        super().__init__()\n",
    "\n",
    "        obs_dim = observation_space.shape[0]\n",
    "\n",
    "        # policy builder depends on action space\n",
    "        if isinstance(action_space, Box):\n",
    "            self.pi = MLPGaussianActor(obs_dim, action_space.shape[0], hidden_sizes, activation)\n",
    "        elif isinstance(action_space, Discrete):\n",
    "            self.pi = MLPCategoricalActor(obs_dim, action_space.n, hidden_sizes, activation)\n",
    "\n",
    "        # build value function\n",
    "        self.v = MLPCritic(obs_dim, hidden_sizes, activation)\n",
    "\n",
    "    def step(self, obs):\n",
    "        with torch.no_grad():\n",
    "            pi = self.pi._distribution(obs)\n",
    "            a = pi.sample()\n",
    "            logp_a = self.pi._log_prob_from_distribution(pi, a)\n",
    "            v = self.v(obs)\n",
    "        return a.numpy(), v.numpy(), logp_a.numpy()\n",
    "\n",
    "    def act(self, obs):\n",
    "        return self.step(obs)[0]\n",
    "\n",
    "\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSOtVl4o91aF"
   },
   "outputs": [],
   "source": [
    "class PPOBuffer:\n",
    "    \"\"\"\n",
    "    A buffer for storing trajectories experienced by a PPO agent interacting\n",
    "    with the environment, and using Generalized Advantage Estimation (GAE-Lambda)\n",
    "    for calculating the advantages of state-action pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, size, gamma=0.99, lam=0.95):\n",
    "        self.obs_buf = np.zeros(core.combined_shape(size, obs_dim), dtype=np.float32)\n",
    "        self.act_buf = np.zeros(core.combined_shape(size, act_dim), dtype=np.float32)\n",
    "        self.adv_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.rew_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ret_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.val_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.logp_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.gamma, self.lam = gamma, lam\n",
    "        self.ptr, self.path_start_idx, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, val, logp):\n",
    "        \"\"\"\n",
    "        Append one timestep of agent-environment interaction to the buffer.\n",
    "        \"\"\"\n",
    "        assert self.ptr < self.max_size     # buffer has to have room so you can store\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.act_buf[self.ptr] = act\n",
    "        self.rew_buf[self.ptr] = rew.item()\n",
    "        self.val_buf[self.ptr] = val.item()\n",
    "        self.logp_buf[self.ptr] = logp.item()\n",
    "        self.ptr += 1\n",
    "\n",
    "    def finish_path(self, last_val=0):\n",
    "        \"\"\"\n",
    "        Call this at the end of a trajectory, or when one gets cut off\n",
    "        by an epoch ending. This looks back in the buffer to where the\n",
    "        trajectory started, and uses rewards and value estimates from\n",
    "        the whole trajectory to compute advantage estimates with GAE-Lambda,\n",
    "        as well as compute the rewards-to-go for each state, to use as\n",
    "        the targets for the value function.\n",
    "\n",
    "        The \"last_val\" argument should be 0 if the trajectory ended\n",
    "        because the agent reached a terminal state (died), and otherwise\n",
    "        should be V(s_T), the value function estimated for the last state.\n",
    "        This allows us to bootstrap the reward-to-go calculation to account\n",
    "        for timesteps beyond the arbitrary episode horizon (or epoch cutoff).\n",
    "        \"\"\"\n",
    "\n",
    "        path_slice = slice(self.path_start_idx, self.ptr)\n",
    "        rews = np.append(self.rew_buf[path_slice], last_val)\n",
    "        vals = np.append(self.val_buf[path_slice], last_val)\n",
    "\n",
    "        # the next two lines implement GAE-Lambda advantage calculation\n",
    "        deltas = rews[:-1] + self.gamma * vals[1:] - vals[:-1]\n",
    "        self.adv_buf[path_slice] = core.discount_cumsum(deltas, self.gamma * self.lam)\n",
    "\n",
    "        # the next line computes rewards-to-go, to be targets for the value function\n",
    "        self.ret_buf[path_slice] = core.discount_cumsum(rews, self.gamma)[:-1]\n",
    "\n",
    "        self.path_start_idx = self.ptr\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"\n",
    "        Call this at the end of an epoch to get all of the data from\n",
    "        the buffer, with advantages appropriately normalized (shifted to have\n",
    "        mean zero and std one). Also, resets some pointers in the buffer.\n",
    "        \"\"\"\n",
    "        assert self.ptr == self.max_size    # buffer has to be full before you can get\n",
    "        self.ptr, self.path_start_idx = 0, 0\n",
    "        # the next two lines implement the advantage normalization trick\n",
    "        adv_mean, adv_std = mpi_statistics_scalar(self.adv_buf)\n",
    "        self.adv_buf = (self.adv_buf - adv_mean) / adv_std\n",
    "        data = dict(obs=self.obs_buf, act=self.act_buf, ret=self.ret_buf,\n",
    "                    adv=self.adv_buf, logp=self.logp_buf)\n",
    "        return {k: torch.as_tensor(v, dtype=torch.float32) for k,v in data.items()}\n",
    "\n",
    "\n",
    "#End definition class PPOBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yd6Dz0YJ-QrG"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ppo(\n",
    "    env_fn,\n",
    "    actor_critic=MLPActorCritic,\n",
    "    ac_kwargs=dict(hidden_sizes=[256, 128], activation=torch.nn.ReLU),\n",
    "    seed=42,\n",
    "    steps_per_epoch=8000,  # Larger batch size for better gradient estimation\n",
    "    epochs=50,  # More epochs for convergence in a volatile environment\n",
    "    gamma=0.995,  # Higher discount factor to account for long-term rewards\n",
    "    clip_ratio=0.7,  # it's 90% clipping when Reduced clip ratio for stable updates\n",
    "    pi_lr=3e-5,  # Lower policy learning rate\n",
    "    vf_lr=1e-4,  # Lower value function learning rate\n",
    "    train_pi_iters=100,  # Increased policy training iterations\n",
    "    train_v_iters=100,  # Increased value function training iterations\n",
    "    lam=0.95,  # GAE smoothing factor for advantage estimation\n",
    "    max_ep_len=1000,  # Typical trading day or customizable period\n",
    "    target_kl=0.35,  # relaxed KL divergence limit\n",
    "    logger_kwargs=dict(),\n",
    "    save_freq=5  # Save checkpoints more frequently\n",
    "):\n",
    "\n",
    "#OLD PPO hyperparameters:\n",
    "\n",
    "#def ppo(env_fn, actor_critic=MLPActorCritic, ac_kwargs=dict(), seed=0,\n",
    " #       steps_per_epoch=4000, epochs=50, gamma=0.99, clip_ratio=0.2, pi_lr=3e-4,\n",
    "  #      vf_lr=1e-3, train_pi_iters=80, train_v_iters=80, lam=0.97, max_ep_len=1000,\n",
    "   #     target_kl=0.01, logger_kwargs=dict(), save_freq=10):\n",
    "    \"\"\"\n",
    "    Proximal Policy Optimization (by clipping),\n",
    "\n",
    "    with early stopping based on approximate KL\n",
    "\n",
    "    Args:\n",
    "        env_fn : A function which creates a copy of the environment.\n",
    "            The environment must satisfy the OpenAI Gym API.\n",
    "\n",
    "        actor_critic: The constructor method for a PyTorch Module with a\n",
    "            ``step`` method, an ``act`` method, a ``pi`` module, and a ``v``\n",
    "            module. The ``step`` method should accept a batch of observations\n",
    "            and return:\n",
    "\n",
    "            ===========  ================  ======================================\n",
    "            Symbol       Shape             Description\n",
    "            ===========  ================  ======================================\n",
    "            ``a``        (batch, act_dim)  | Numpy array of actions for each\n",
    "                                           | observation.\n",
    "            ``v``        (batch,)          | Numpy array of value estimates\n",
    "                                           | for the provided observations.\n",
    "            ``logp_a``   (batch,)          | Numpy array of log probs for the\n",
    "                                           | actions in ``a``.\n",
    "            ===========  ================  ======================================\n",
    "\n",
    "            The ``act`` method behaves the same as ``step`` but only returns ``a``.\n",
    "\n",
    "            The ``pi`` module's forward call should accept a batch of\n",
    "            observations and optionally a batch of actions, and return:\n",
    "\n",
    "            ===========  ================  ======================================\n",
    "            Symbol       Shape             Description\n",
    "            ===========  ================  ======================================\n",
    "            ``pi``       N/A               | Torch Distribution object, containing\n",
    "                                           | a batch of distributions describing\n",
    "                                           | the policy for the provided observations.\n",
    "            ``logp_a``   (batch,)          | Optional (only returned if batch of\n",
    "                                           | actions is given). Tensor containing\n",
    "                                           | the log probability, according to\n",
    "                                           | the policy, of the provided actions.\n",
    "                                           | If actions not given, will contain\n",
    "                                           | ``None``.\n",
    "            ===========  ================  ======================================\n",
    "\n",
    "            The ``v`` module's forward call should accept a batch of observations\n",
    "            and return:\n",
    "\n",
    "            ===========  ================  ======================================\n",
    "            Symbol       Shape             Description\n",
    "            ===========  ================  ======================================\n",
    "            ``v``        (batch,)          | Tensor containing the value estimates\n",
    "                                           | for the provided observations. (Critical:\n",
    "                                           | make sure to flatten this!)\n",
    "            ===========  ================  ======================================\n",
    "\n",
    "\n",
    "        ac_kwargs (dict): Any kwargs appropriate for the ActorCritic object\n",
    "            you provided to PPO.\n",
    "\n",
    "        seed (int): Seed for random number generators.\n",
    "\n",
    "        steps_per_epoch (int): Number of steps of interaction (state-action pairs)\n",
    "            for the agent and the environment in each epoch.\n",
    "\n",
    "        epochs (int): Number of epochs of interaction (equivalent to\n",
    "            number of policy updates) to perform.\n",
    "\n",
    "        gamma (float): Discount factor. (Always between 0 and 1.)\n",
    "\n",
    "        clip_ratio (float): Hyperparameter for clipping in the policy objective.\n",
    "            Roughly: how far can the new policy go from the old policy while\n",
    "            still profiting (improving the objective function)? The new policy\n",
    "            can still go farther than the clip_ratio says, but it doesn't help\n",
    "            on the objective anymore. (Usually small, 0.1 to 0.3.) Typically\n",
    "            denoted by :math:`\\epsilon`.\n",
    "\n",
    "        pi_lr (float): Learning rate for policy optimizer.\n",
    "\n",
    "        vf_lr (float): Learning rate for value function optimizer.\n",
    "\n",
    "        train_pi_iters (int): Maximum number of gradient descent steps to take\n",
    "            on policy loss per epoch. (Early stopping may cause optimizer\n",
    "            to take fewer than this.)\n",
    "\n",
    "        train_v_iters (int): Number of gradient descent steps to take on\n",
    "            value function per epoch.\n",
    "\n",
    "        lam (float): Lambda for GAE-Lambda. (Always between 0 and 1,\n",
    "            close to 1.)\n",
    "\n",
    "        max_ep_len (int): Maximum length of trajectory / episode / rollout.\n",
    "\n",
    "        target_kl (float): Roughly what KL divergence we think is appropriate\n",
    "            between new and old policies after an update. This will get used\n",
    "            for early stopping. (Usually small, 0.01 or 0.05.)\n",
    "\n",
    "        logger_kwargs (dict): Keyword args for EpochLogger.\n",
    "\n",
    "        save_freq (int): How often (in terms of gap between epochs) to save\n",
    "            the current policy and value function.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Special function to avoid certain slowdowns from PyTorch + MPI combo.\n",
    "    setup_pytorch_for_mpi()\n",
    "\n",
    "    # Set up logger and save configuration\n",
    "    logger = EpochLogger(**logger_kwargs)\n",
    "    logger.save_config(locals())\n",
    "\n",
    "    # Random seed\n",
    "    seed += 10000 * proc_id()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Instantiate environment\n",
    "    env = env_fn()\n",
    "    obs_dim = env.observation_space.shape\n",
    "    act_dim = env.action_space.shape\n",
    "\n",
    "\n",
    "    print(\"obs dim \" + str(obs_dim))\n",
    "    print(\"act dim \" + str(act_dim))\n",
    "\n",
    "    # Create actor-critic module\n",
    "    ac = actor_critic(env.observation_space, env.action_space, **ac_kwargs)\n",
    "\n",
    "    # Sync params across processes\n",
    "    sync_params(ac)\n",
    "\n",
    "    # Count variables\n",
    "    var_counts = tuple(core.count_vars(module) for module in [ac.pi, ac.v])\n",
    "    logger.log('\\nNumber of parameters: \\t pi: %d, \\t v: %d\\n'%var_counts)\n",
    "\n",
    "    # Set up experience buffer\n",
    "    local_steps_per_epoch = int(steps_per_epoch / num_procs())\n",
    "    buf = PPOBuffer(obs_dim, act_dim, local_steps_per_epoch, gamma, lam)\n",
    "\n",
    "    # Set up function for computing PPO policy loss\n",
    "    def compute_loss_pi(data):\n",
    "        obs, act, adv, logp_old = data['obs'], data['act'], data['adv'], data['logp']\n",
    "\n",
    "        # Policy loss\n",
    "        pi, logp = ac.pi(obs, act)\n",
    "        ratio = torch.exp(logp - logp_old)\n",
    "        clip_adv = torch.clamp(ratio, 1-clip_ratio, 1+clip_ratio) * adv\n",
    "        loss_pi = -(torch.min(ratio * adv, clip_adv)).mean()\n",
    "\n",
    "        # Useful extra info\n",
    "        approx_kl = (logp_old - logp).mean().item()\n",
    "        ent = pi.entropy().mean().item()\n",
    "        clipped = ratio.gt(1+clip_ratio) | ratio.lt(1-clip_ratio)\n",
    "        clipfrac = torch.as_tensor(clipped, dtype=torch.float32).mean().item()\n",
    "        pi_info = dict(kl=approx_kl, ent=ent, cf=clipfrac)\n",
    "\n",
    "        return loss_pi, pi_info\n",
    "\n",
    "    # Set up function for computing value loss\n",
    "    def compute_loss_v(data):\n",
    "        obs, ret = data['obs'], data['ret']\n",
    "        return ((ac.v(obs) - ret)**2).mean()\n",
    "\n",
    "    # Set up optimizers for policy and value function\n",
    "    pi_optimizer = Adam(ac.pi.parameters(), lr=pi_lr)\n",
    "    vf_optimizer = Adam(ac.v.parameters(), lr=vf_lr)\n",
    "\n",
    "    # Set up model saving\n",
    "    logger.setup_pytorch_saver(ac)\n",
    "\n",
    "    def update():\n",
    "        data = buf.get()\n",
    "\n",
    "        pi_l_old, pi_info_old = compute_loss_pi(data)\n",
    "        pi_l_old = pi_l_old.item()\n",
    "        v_l_old = compute_loss_v(data).item()\n",
    "\n",
    "        # Train policy with multiple steps of gradient descent\n",
    "        for i in range(train_pi_iters):\n",
    "            pi_optimizer.zero_grad()\n",
    "            loss_pi, pi_info = compute_loss_pi(data)\n",
    "            kl = mpi_avg(pi_info['kl'])\n",
    "            if kl > 1.5 * target_kl:\n",
    "                logger.log('Early stopping at step %d due to reaching max kl.'%i)\n",
    "                break\n",
    "            loss_pi.backward()\n",
    "            mpi_avg_grads(ac.pi)    # average grads across MPI processes\n",
    "            pi_optimizer.step()\n",
    "\n",
    "        logger.store(StopIter=i)\n",
    "\n",
    "        # Value function learning\n",
    "        for i in range(train_v_iters):\n",
    "            vf_optimizer.zero_grad()\n",
    "            loss_v = compute_loss_v(data)\n",
    "            loss_v.backward()\n",
    "            mpi_avg_grads(ac.v)    # average grads across MPI processes\n",
    "            vf_optimizer.step()\n",
    "\n",
    "        # Log changes from update\n",
    "        kl, ent, cf = pi_info['kl'], pi_info_old['ent'], pi_info['cf']\n",
    "        logger.store(LossPi=pi_l_old, LossV=v_l_old,\n",
    "                     KL=kl, Entropy=ent, ClipFrac=cf,\n",
    "                     DeltaLossPi=(loss_pi.item() - pi_l_old),\n",
    "                     DeltaLossV=(loss_v.item() - v_l_old))\n",
    "\n",
    "    # Prepare for interaction with environment\n",
    "    start_time = time.time()\n",
    "    o, ep_ret, ep_len = env.reset(), 0, 0\n",
    "\n",
    "    # Main loop: collect experience in env and update/log each epoch\n",
    "    for epoch in range(epochs):\n",
    "        for t in range(local_steps_per_epoch):\n",
    "            a, v, logp = ac.step(torch.as_tensor(o, dtype=torch.float32))\n",
    "            #print(\"🔥 PPO received state:\", o.shape)\n",
    "\n",
    "            next_o, r, d, _ = env.step(a)\n",
    "            ep_ret += r\n",
    "            ep_len += 1\n",
    "\n",
    "            # save and log\n",
    "            buf.store(o, a, r, v, logp)\n",
    "            logger.store(VVals=v)\n",
    "\n",
    "            # Update obs (critical!)\n",
    "            o = next_o\n",
    "\n",
    "            timeout = ep_len == max_ep_len\n",
    "            terminal = d or timeout\n",
    "            epoch_ended = t==local_steps_per_epoch-1\n",
    "\n",
    "            if terminal or epoch_ended:\n",
    "                if epoch_ended and not(terminal):\n",
    "                    print('Warning: trajectory cut off by epoch at %d steps.'%ep_len, flush=True)\n",
    "                # if trajectory didn't reach terminal state, bootstrap value target\n",
    "                if timeout or epoch_ended:\n",
    "                    _, v, _ = ac.step(torch.as_tensor(o, dtype=torch.float32))\n",
    "                else:\n",
    "                    v = 0\n",
    "                buf.finish_path(v)\n",
    "                if terminal:\n",
    "                    # only save EpRet / EpLen if trajectory finished\n",
    "                    logger.store(EpRet=ep_ret, EpLen=ep_len)\n",
    "                o, ep_ret, ep_len = env.reset(), 0, 0\n",
    "\n",
    "\n",
    "        # Save model\n",
    "        if (epoch % save_freq == 0) or (epoch == epochs-1):\n",
    "            logger.save_state({'env': env}, None)\n",
    "\n",
    "        # Perform PPO update!\n",
    "        update()\n",
    "\n",
    "        # Log info about epoch\n",
    "        logger.log_tabular('Epoch', epoch)\n",
    "        logger.log_tabular('EpRet', with_min_and_max=True)\n",
    "        logger.log_tabular('EpLen', average_only=True)\n",
    "        logger.log_tabular('VVals', with_min_and_max=True)\n",
    "        logger.log_tabular('TotalEnvInteracts', (epoch+1)*steps_per_epoch)\n",
    "        logger.log_tabular('LossPi', average_only=True)\n",
    "        logger.log_tabular('LossV', average_only=True)\n",
    "        logger.log_tabular('DeltaLossPi', average_only=True)\n",
    "        logger.log_tabular('DeltaLossV', average_only=True)\n",
    "        logger.log_tabular('Entropy', average_only=True)\n",
    "        logger.log_tabular('KL', average_only=True)\n",
    "        logger.log_tabular('ClipFrac', average_only=True)\n",
    "        logger.log_tabular('StopIter', average_only=True)\n",
    "        logger.log_tabular('Time', time.time()-start_time)\n",
    "        logger.dump_tabular()\n",
    "    return ac\n",
    "\n",
    "\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1744710936494,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "B1C1G8d8-Suy",
    "outputId": "13e3da5b-5d6b-4d96-85a2-63c1312bbecc"
   },
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--env', type=str, default=env_train) #'HalfCheetah-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1744710937297,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "mi9jlWLh-aoh",
    "outputId": "2361d06c-f316-4731-decd-15b051a1326d"
   },
   "outputs": [],
   "source": [
    "#parser.add_argument('--hid', type=int, default=64)\n",
    "#parser.add_argument('--l', type=int, default=2)\n",
    "#parser.add_argument('--gamma', type=float, default=0.99)\n",
    "#parser.add_argument('--seed', '-s', type=int, default=0)\n",
    "#parser.add_argument('--cpu', type=int, default=4)\n",
    "#parser.add_argument('--steps', type=int, default=4000)\n",
    "#parser.add_argument('--epochs', type=int, default=50)\n",
    "#parser.add_argument('--exp_name', type=str, default='ppo')\n",
    "\n",
    "\n",
    "\n",
    "# Parser arguments adapted to hyperparameter optimization by chatGPT\n",
    "\n",
    "parser.add_argument('--hid', type=int, default=512)  # Updated to match the first hidden size in ac_kwargs\n",
    "parser.add_argument('--l', type=int, default=2)  # Updated to match the number of layers in ac_kwargs\n",
    "parser.add_argument('--gamma', type=float, default=0.995)  # Updated to match gamma in ppo\n",
    "parser.add_argument('--seed', '-s', type=int, default=42)  # Updated to match seed in ppo\n",
    "parser.add_argument('--cpu', type=int, default=4)  # Kept as is since it's not in ppo\n",
    "parser.add_argument('--steps', type=int, default=8000) #8000)  # Updated to match steps_per_epoch in ppo\n",
    "parser.add_argument('--epochs', type=int, default=50) # 10 for test otherwise 100 it is too much 150)  # Updated to match epochs in ppo\n",
    "parser.add_argument('--exp_name', type=str, default='ppo')  # Kept as is since it's not in ppo\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1744710941741,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "Dl7lhGnS-ar7",
    "outputId": "5443ed82-fca1-46fe-da6a-a339db807bc4"
   },
   "outputs": [],
   "source": [
    "#parser.add_argument('-f', '--file', type=str, help='Kernel connection file')  # Add this line\n",
    "parser.add_argument('extra_args', nargs=argparse.REMAINDER)  # Catch-all for unrecognized arguments\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "#mpi_fork(args.cpu)  # run parallel code with mpi  doesn't work in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COOQSRSj_XwW"
   },
   "outputs": [],
   "source": [
    "# Add this line to ignore unknown args\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4426197,
     "status": "ok",
     "timestamp": 1744715369208,
     "user": {
      "displayName": "Huma Ameer",
      "userId": "09038294176164290895"
     },
     "user_tz": -300
    },
    "id": "qNZsiGfK4iVh",
    "outputId": "0fd39158-6ff4-4a7d-912c-96e27c16efd4"
   },
   "outputs": [],
   "source": [
    "\n",
    "from spinup.utils.run_utils import setup_logger_kwargs\n",
    "\n",
    "\n",
    "logger_kwargs = setup_logger_kwargs(args.exp_name, args.seed)\n",
    "\n",
    "trained_ppo=ppo(lambda : args.env, actor_critic=MLPActorCritic,\n",
    "        ac_kwargs=dict(hidden_sizes=[args.hid]*args.l), gamma=args.gamma,\n",
    "        seed=args.seed, steps_per_epoch=args.steps, epochs=args.epochs,\n",
    "        logger_kwargs=logger_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model_path_mother_sister = \"/content/drive/My Drive/FinRL/finrl_ppo_models/\"\n",
    "model_path = model_path_mother_sister + \"/agent_ppo_deepseek_50_epochs_8k_steps_01_cpu.pth\"\n",
    "# model_path = TRAINED_MODEL_DIR + \"/agent_ppo_deepseek_100_epochs_20k_steps_01.pth\"\n",
    "torch.save(trained_ppo.state_dict(), model_path)\n",
    "print(\"Training finished and saved in \" + model_path)\n",
    "# Load the model\n",
    "#loaded_ppo = MLPActorCritic()\n",
    "#loaded_ppo.load_state_dict(torch.load(model_path))\n",
    "#loaded_ppo.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "\n",
    "#trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\")\n",
    "\n",
    "\n",
    "# ## Save the trained agent\n",
    "# Trained agents should have already been saved in the \"trained_models\" drectory after you run the code blocks above.\n",
    "#\n",
    "# For Colab users, the zip files should be at \"./trained_models\" or \"/content/trained_models\".\n",
    "#\n",
    "# For users running on your local environment, the zip files should be at \"./trained_models\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qLiCUa698ZQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6B1Z8zU8ZQlY",
    "1AWIRTyxZMBP",
    "oEGoSFeQ-7rB",
    "RwdzzGOt_Beo",
    "4tG3jgdaNksR"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "078504f804d04f01906a24e09a9c971b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85c712ddfd68480f8e3790654f6aa6a2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_54f4d72c1e03437496e5abcd64566a1d",
      "value": 1
     }
    },
    "16b7182d88c944788bb022c3c7bef310": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d548c00cb4f4b14969551da1a7e4bb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecce6be7b44b4e81abf77b1742accc85",
      "placeholder": "​",
      "style": "IPY_MODEL_773765f711ac4c1588004d2e83e42de7",
      "value": "(…)in_data_deepseek_sentiment_2013_2018.csv: 100%"
     }
    },
    "250ae613e0534db58a975b567e6ceae0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27c3867f583d41998f32c8ec66c7c941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe09d0b264184aa8a34c45075950829e",
      "placeholder": "​",
      "style": "IPY_MODEL_16b7182d88c944788bb022c3c7bef310",
      "value": "Generating train split: "
     }
    },
    "363b92ecc9cd42599bfe920cdedf1ac6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d38c189cb8b494abf4a7e296c648143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27c3867f583d41998f32c8ec66c7c941",
       "IPY_MODEL_078504f804d04f01906a24e09a9c971b",
       "IPY_MODEL_91c6b7ebbb0f4abc94e7e3940dd94f0d"
      ],
      "layout": "IPY_MODEL_e4ef9282c35e46e882d94158a7edcc84"
     }
    },
    "40f9327cce5c4a84996a31782e6ce756": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a328d17ae2047c7ad889887133c18b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54f4d72c1e03437496e5abcd64566a1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5f92eec74cb24a98b443c8443091444f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "604c35e508e7481a9b4a664e14c947c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64d74c163c354a1985380bcbe5d136b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66dee62bb472498f84705eb5018342f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dee4e080884465886bebc88242936a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "773765f711ac4c1588004d2e83e42de7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83ecc68c4f784cfdadf780909499bb87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85c712ddfd68480f8e3790654f6aa6a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "8a7d1091fb86416bb54cf63894573ae3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91c6b7ebbb0f4abc94e7e3940dd94f0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_604c35e508e7481a9b4a664e14c947c5",
      "placeholder": "​",
      "style": "IPY_MODEL_9a7c4d41491b4a4483d7b5590e4f94e8",
      "value": " 126756/0 [00:00&lt;00:00, 157843.07 examples/s]"
     }
    },
    "9a7c4d41491b4a4483d7b5590e4f94e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b361154eef7f4fe4bd9a86507177b893": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e9194524c5d843588c7b3f703099ff58",
       "IPY_MODEL_f9f6aebf33754f37b9bc6e4cc4d287ac",
       "IPY_MODEL_f9860896c6874eb2b785f34b23788fa9"
      ],
      "layout": "IPY_MODEL_64d74c163c354a1985380bcbe5d136b7"
     }
    },
    "b9d1c20db240488b85df7ff38b65e12b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d17f19d0f4b14bef976c7c3730006ecb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e358908327254e5db48fc8d44efafa08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d548c00cb4f4b14969551da1a7e4bb0",
       "IPY_MODEL_f9f3aea138f446bc8b75d5970c909025",
       "IPY_MODEL_f18f69110e514bcc90dc3ce769430811"
      ],
      "layout": "IPY_MODEL_66dee62bb472498f84705eb5018342f0"
     }
    },
    "e4ef9282c35e46e882d94158a7edcc84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9194524c5d843588c7b3f703099ff58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a7d1091fb86416bb54cf63894573ae3",
      "placeholder": "​",
      "style": "IPY_MODEL_4a328d17ae2047c7ad889887133c18b2",
      "value": "README.md: 100%"
     }
    },
    "ecce6be7b44b4e81abf77b1742accc85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f18f69110e514bcc90dc3ce769430811": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f92eec74cb24a98b443c8443091444f",
      "placeholder": "​",
      "style": "IPY_MODEL_250ae613e0534db58a975b567e6ceae0",
      "value": " 37.0M/37.0M [00:00&lt;00:00, 74.2MB/s]"
     }
    },
    "f9860896c6874eb2b785f34b23788fa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d17f19d0f4b14bef976c7c3730006ecb",
      "placeholder": "​",
      "style": "IPY_MODEL_83ecc68c4f784cfdadf780909499bb87",
      "value": " 43.0/43.0 [00:00&lt;00:00, 2.10kB/s]"
     }
    },
    "f9f3aea138f446bc8b75d5970c909025": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dee4e080884465886bebc88242936a7",
      "max": 36968872,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40f9327cce5c4a84996a31782e6ce756",
      "value": 36968872
     }
    },
    "f9f6aebf33754f37b9bc6e4cc4d287ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_363b92ecc9cd42599bfe920cdedf1ac6",
      "max": 43,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b9d1c20db240488b85df7ff38b65e12b",
      "value": 43
     }
    },
    "fe09d0b264184aa8a34c45075950829e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
